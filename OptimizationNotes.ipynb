{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "**__Article__**:\n",
    "\n",
    "https://towardsdatascience.com/hyperparameter-optimization-intro-and-implementation-of-grid-search-random-search-and-bayesian-b2f16c00578a\n",
    "\n",
    "This notebook will be my notes on the article on towardsdatascience about Hyperparameter Optimization. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search\n",
    "* Grid Search is a brute force method of looping through each combination of hyperparameters in the given search space. \n",
    "* It works, but its time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected hyperparameters:\n",
      "{'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 500}\n",
      "\n",
      "best_score: 0.9666666666666668\n",
      "elapsed_time: 211.0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import time\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "search_space = {'n_estimators': [10, 100, 500, 1000],\n",
    "              'max_depth': [2, 10, 25, 50, 100],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 5, 10]}\n",
    "\n",
    "# Define the random forest classifier\n",
    "clf = RandomForestClassifier(random_state=1234)\n",
    "\n",
    "# Create the optimizer object\n",
    "optimizer = GridSearchCV(clf, search_space, cv=5, scoring='accuracy')\n",
    "\n",
    "# Store start time to calculate total elapsed time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the optimizer on the data\n",
    "optimizer.fit(X, y)\n",
    "\n",
    "# Store end time to calculate total elapsed time\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the best set of hyperparameters and corresponding score\n",
    "print(f\"selected hyperparameters:\")\n",
    "print(optimizer.best_params_)\n",
    "print(\"\")\n",
    "print(f\"best_score: {optimizer.best_score_}\")\n",
    "print(f\"elapsed_time: {round(end_time-start_time, 1)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Search\n",
    "* Random search will randomly sampling hyperparameter combinations from a given search space, instead of going through each variation. \n",
    "* It can be much faster than GridSearch, but may miss the best value due to randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected hyperparameters:\n",
      "{'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 100}\n",
      "\n",
      "best_score: 0.9666666666666668\n",
      "elapsed_time: 68.3\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Create a RandomizedSearchCV object\n",
    "optimizer = RandomizedSearchCV(clf, param_distributions=search_space,\n",
    "                               n_iter=50, cv=5, scoring='accuracy',\n",
    "                               random_state=1234)\n",
    "\n",
    "# Store start time to calculate total elapsed time\n",
    "start_time = time.time()\n",
    "\n",
    "# Fit the optimizer on the data\n",
    "optimizer.fit(X, y)\n",
    "\n",
    "# Store end time to calculate total elapsed time\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the best set of hyperparameters and corresponding score\n",
    "print(f\"selected hyperparameters:\")\n",
    "print(optimizer.best_params_)\n",
    "print(\"\")\n",
    "print(f\"best_score: {optimizer.best_score_}\")\n",
    "print(f\"elapsed_time: {round(end_time-start_time, 1)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization\n",
    "* Bayesian tries to use probabalistic models to try and \"learn\" from previously attempted combinations of hyperparameters. \n",
    "* Broken into 4 steps:\n",
    "    1. Define a prior model. The probabilistic model of what we think the hyperparameters are at a given time\n",
    "    2. Evaluate the model for a sample of hyperparameters\n",
    "    3. Update the prior model to a posterior model. Think y and y_hat.\n",
    "    4. Repeat until y and y_hat converge, resources are exhausted, or some other pre-defined metric is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected hyperparameters:\n",
      "OrderedDict([('max_depth', 25), ('min_samples_leaf', 5), ('min_samples_split', 5), ('n_estimators', 10)])\n",
      "\n",
      "best_score: 0.9666666666666668\n",
      "elapsed_time: 19.0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "optimizer = BayesSearchCV(estimator=RandomForestClassifier(),\n",
    "                          search_spaces=search_space,\n",
    "                          n_iter=10,\n",
    "                          cv=5,\n",
    "                          scoring='accuracy',\n",
    "                          random_state=1234)\n",
    "\n",
    "# Store start time to calculate total elapsed time\n",
    "start_time = time.time()\n",
    "\n",
    "optimizer.fit(X, y)\n",
    "\n",
    "# Store end time to calculate total elapsed time\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the best set of hyperparameters and corresponding score\n",
    "print(f\"selected hyperparameters:\")\n",
    "print(optimizer.best_params_)\n",
    "print(\"\")\n",
    "print(f\"best_score: {optimizer.best_score_}\")\n",
    "print(f\"elapsed_time: {round(end_time-start_time, 1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61cc4aa9b3d4b107b91d75d4e5c2dc050028b63fe8006f5e800bbd45a0523348"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
